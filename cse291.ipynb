{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "#remove the compute edge\n",
        "def preProcessGraph(G):\n",
        "  m,n=G.size()\n",
        "  for i in range(m):\n",
        "    for j in range(i,n):\n",
        "      if G[i,j]>0 and G[j,i]>0:\n",
        "        G[j,i]=0\n",
        "  return G\n",
        "\n",
        "# make the Graph be an upper triangle graph,\n",
        "def preProcessDigGraph(G):\n",
        "   m,n=G.size()\n",
        "   for i in range(m):\n",
        "    for j in range(i,n):\n",
        "      G[j,i]=0\n",
        "   return G\n",
        "\n",
        "def findStart(G):\n",
        "  m,n=G.size()\n",
        "  result=torch.ones(m)\n",
        "  for i in range(m):\n",
        "    tmp=G[:,i]\n",
        "    tmp1=tmp.sum()\n",
        "    if tmp1>0:\n",
        "      result[i]=0\n",
        "  return result\n",
        "\n",
        "def testG():\n",
        "  G=torch.tensor([[1,0,1],[1,1,1],[1,1,1]])\n",
        "  print(G)\n",
        "  P=preProcessGraph(G)\n",
        "  print(P)\n",
        "\n",
        "  re1=findStart(P)\n",
        "  print(re1)\n",
        "\n",
        "  re2=preProcessDigGraph(G)\n",
        "  print(re2)\n",
        "testG() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdyfbMF1iQIb",
        "outputId": "b94995b9-db7a-4d90-b1b1-3d5a6aa39a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 0, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]])\n",
            "tensor([[0, 0, 1],\n",
            "        [1, 0, 1],\n",
            "        [0, 0, 0]])\n",
            "tensor([0., 1., 0.])\n",
            "tensor([[0, 0, 1],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. weight: every edge has two weight, [w,b], w is N√óN, b is also N√óN\n",
        " 2. every node has 8 weights, Œº, œÉ, A,w,phi,b k*N(Œº, œÉ)+A sin(wt+Œ¶)+b; the demision is N√ó8\n",
        " 3. the output is y= ‚àëk*ùê∫(t,Œº, œÉ)+Asin(wt+Œ¶)+b\n",
        " 4. loss=mse||y-input||^2\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "IGJOjOGByLgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd.grad_mode import no_grad\n",
        "from math import exp\n",
        "import torch\n",
        "\n",
        "data=torch.tensor([1.,4.,3.,2.,4.,3.],requires_grad=False)\n",
        "data_size=data.size()\n",
        "# print(data_size[0])\n",
        "\n",
        "node_size=6\n",
        "#generate a graph\n",
        "graph=torch.ones(node_size,node_size)\n",
        "\n",
        "#processing the graph\n",
        "post_graph=preProcessDigGraph(graph)\n",
        "\n",
        "print(post_graph)\n",
        "\n",
        "#input should all be ones, dimension is node size\n",
        "input=torch.ones(node_size)\n",
        "\n",
        "#the output is data size\n",
        "output=torch.zeros(node_size,data_size[0])\n",
        "finalout=torch.zeros(data_size[0])\n",
        "# nodeOut=torch.zeros(node_size,requires_grad=True)\n",
        "nodeEnergy=torch.ones(node_size)\n",
        "\n",
        "#node weight and bias\n",
        "weight=torch.rand(node_size,node_size,requires_grad=True)\n",
        "bias=torch.rand(node_size,node_size,requires_grad=True)\n",
        "\n",
        "#output param\n",
        "mu=torch.rand(node_size)\n",
        "sigma=torch.rand(node_size)\n",
        "K=torch.rand(node_size)\n",
        "A=torch.rand(node_size)\n",
        "omega=torch.rand(node_size)\n",
        "phi=torch.rand(node_size)\n",
        "outBias=torch.rand(node_size)\n",
        "\n",
        "weight_mu=torch.rand(node_size,requires_grad=True)\n",
        "bias_mu=torch.rand(node_size,requires_grad=True)\n",
        "\n",
        "weight_sigma=torch.rand(node_size,requires_grad=True)\n",
        "bias_sigma=torch.rand(node_size,requires_grad=True)\n",
        "\n",
        "weight_K=torch.rand(node_size,requires_grad=True)\n",
        "bias_K=torch.rand(node_size,requires_grad=True)\n",
        "\n",
        "weight_A=torch.rand(node_size,requires_grad=True)\n",
        "bias_A=torch.rand(node_size,requires_grad=True)\n",
        "\n",
        "weight_omega=torch.rand(node_size,requires_grad=True)\n",
        "bias_omega=torch.rand(node_size,requires_grad=True)\n",
        "\n",
        "weight_phi=torch.rand(node_size,requires_grad=True)\n",
        "bias_phi=torch.rand(node_size,requires_grad=True)\n",
        "\n",
        "weight_outBias=torch.rand(node_size,requires_grad=True)\n",
        "bias_outBias=torch.rand(node_size,requires_grad=True)\n",
        "nodeOut=torch.rand(node_size,requires_grad=False)\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "learning_rate=torch.tensor([0.001])\n",
        "for iter in range (100):\n",
        "   # only upper diagnal be processed:\n",
        "    for i in range(node_size):\n",
        "      # node energy\n",
        "      nodeOut[i]=weight[i,i]*nodeEnergy[i]+outBias[i]\n",
        "      nodeOut[i]=torch.relu(nodeOut[i])\n",
        "      # tmp=nodeOut.clone()\n",
        "      # for j in range(i,node_size):\n",
        "      #   with torch.no_grad():\n",
        "          # nodeEnergy[j]=nodeEnergy[j]+post_graph[i,j]*(nodeOut[i]*weight[i,j]+bias[i,j])\n",
        "\n",
        "    # for i in range(node_size):\n",
        "    #   mu[i]=weight_mu[i]*nodeOut[i]+bias_mu[i]\n",
        "    #   sigma[i]=weight_sigma[i]*nodeOut[i]+bias_sigma[i]\n",
        "    #   K[i]=weight_K[i]*nodeOut[i]+bias_K[i]\n",
        "    #   A[i]=weight_A[i]*nodeOut[i]+bias_A[i]\n",
        "    #   omega[i]=weight_omega[i]*nodeOut[i]+bias_omega[i]\n",
        "    #   phi[i]=weight_phi[i]*nodeOut[i]+bias_phi[i]\n",
        "    #   outBias[i]=weight_outBias[i]*nodeOut[i]+bias_outBias[i]\n",
        "\n",
        "    # mu.retains_grad  \n",
        "\n",
        "    for i in range(node_size):\n",
        "      # for t in range(data_size[0]):\n",
        "        finalout[i]=weight_mu[i]+nodeOut[i]+bias_mu[i]\n",
        "        # output[i,t]=(K[i]/sigma[i]*torch.exp(-(t-mu[i]).pow(2)/(sigma[i].pow(2)))+A[i]*torch.sin(omega[i]*t+phi[i])+outBias[i])\n",
        "\n",
        "    #get the loss:\n",
        "    # finalout=torch.sum(output,0)\n",
        "\n",
        "\n",
        "    loss=(finalout-data).pow(2).sum()\n",
        "    \n",
        "    loss.backward(retain_graph=True)\n",
        "    print (loss)\n",
        "    # print(finalout)\n",
        "\n",
        "    #update the parameter:\n",
        "    with torch.no_grad():\n",
        "      weight-=learning_rate*weight.grad\n",
        "    #   # bias-=learning_rate*bias.grad\n",
        "\n",
        "      weight_mu-=learning_rate*weight_mu.grad\n",
        "    #   weight_sigma-=learning_rate*weight_sigma.grad\n",
        "    #   weight_K-=learning_rate*weight_K.grad\n",
        "    #   weight_A-=learning_rate*weight_A.grad\n",
        "    #   weight_omega-=learning_rate*weight_omega.grad\n",
        "    #   weight_outBias-=learning_rate*weight_outBias.grad\n",
        "    #   weight_phi-=learning_rate*weight_phi.grad\n",
        "\n",
        "    #   bias_mu-=learning_rate*bias_mu.grad\n",
        "    #   bias_sigma-=learning_rate*bias_sigma.grad\n",
        "    #   bias_K-=learning_rate*bias_K.grad\n",
        "    #   bias_A-=learning_rate*bias_A.grad\n",
        "    #   bias_omega-=learning_rate*bias_omega.grad\n",
        "    #   bias_outBias-=learning_rate*bias_outBias.grad\n",
        "    #   bias_phi-=learning_rate*bias_phi.grad\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW_0fNCC6qlF",
        "outputId": "52f79f00-9483-422c-9cb8-91237b608f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n",
            "tensor(13.5323, grad_fn=<SumBackward0>)\n",
            "tensor(13.4242, grad_fn=<SumBackward0>)\n",
            "tensor(13.2099, grad_fn=<SumBackward0>)\n",
            "tensor(12.8926, grad_fn=<SumBackward0>)\n",
            "tensor(12.4776, grad_fn=<SumBackward0>)\n",
            "tensor(11.9713, grad_fn=<SumBackward0>)\n",
            "tensor(11.3820, grad_fn=<SumBackward0>)\n",
            "tensor(10.7190, grad_fn=<SumBackward0>)\n",
            "tensor(9.9929, grad_fn=<SumBackward0>)\n",
            "tensor(9.2153, grad_fn=<SumBackward0>)\n",
            "tensor(8.3987, grad_fn=<SumBackward0>)\n",
            "tensor(7.5562, grad_fn=<SumBackward0>)\n",
            "tensor(6.7011, grad_fn=<SumBackward0>)\n",
            "tensor(5.8471, grad_fn=<SumBackward0>)\n",
            "tensor(5.0080, grad_fn=<SumBackward0>)\n",
            "tensor(4.1970, grad_fn=<SumBackward0>)\n",
            "tensor(3.4273, grad_fn=<SumBackward0>)\n",
            "tensor(2.7110, grad_fn=<SumBackward0>)\n",
            "tensor(2.0596, grad_fn=<SumBackward0>)\n",
            "tensor(1.4836, grad_fn=<SumBackward0>)\n",
            "tensor(0.9921, grad_fn=<SumBackward0>)\n",
            "tensor(0.5930, grad_fn=<SumBackward0>)\n",
            "tensor(0.2927, grad_fn=<SumBackward0>)\n",
            "tensor(0.0960, grad_fn=<SumBackward0>)\n",
            "tensor(0.0060, grad_fn=<SumBackward0>)\n",
            "tensor(0.0241, grad_fn=<SumBackward0>)\n",
            "tensor(0.1502, grad_fn=<SumBackward0>)\n",
            "tensor(0.3821, grad_fn=<SumBackward0>)\n",
            "tensor(0.7161, grad_fn=<SumBackward0>)\n",
            "tensor(1.1470, grad_fn=<SumBackward0>)\n",
            "tensor(1.6678, grad_fn=<SumBackward0>)\n",
            "tensor(2.2701, grad_fn=<SumBackward0>)\n",
            "tensor(2.9445, grad_fn=<SumBackward0>)\n",
            "tensor(3.6460, grad_fn=<SumBackward0>)\n",
            "tensor(4.3930, grad_fn=<SumBackward0>)\n",
            "tensor(5.1739, grad_fn=<SumBackward0>)\n",
            "tensor(5.9765, grad_fn=<SumBackward0>)\n",
            "tensor(6.7882, grad_fn=<SumBackward0>)\n",
            "tensor(7.5963, grad_fn=<SumBackward0>)\n",
            "tensor(8.3882, grad_fn=<SumBackward0>)\n",
            "tensor(9.1513, grad_fn=<SumBackward0>)\n",
            "tensor(9.8739, grad_fn=<SumBackward0>)\n",
            "tensor(10.5446, grad_fn=<SumBackward0>)\n",
            "tensor(11.1528, grad_fn=<SumBackward0>)\n",
            "tensor(11.6891, grad_fn=<SumBackward0>)\n",
            "tensor(12.1451, grad_fn=<SumBackward0>)\n",
            "tensor(12.5136, grad_fn=<SumBackward0>)\n",
            "tensor(12.7891, grad_fn=<SumBackward0>)\n",
            "tensor(12.9671, grad_fn=<SumBackward0>)\n",
            "tensor(13.0450, grad_fn=<SumBackward0>)\n",
            "tensor(13.0216, grad_fn=<SumBackward0>)\n",
            "tensor(12.8974, grad_fn=<SumBackward0>)\n",
            "tensor(12.6744, grad_fn=<SumBackward0>)\n",
            "tensor(12.3562, grad_fn=<SumBackward0>)\n",
            "tensor(11.9480, grad_fn=<SumBackward0>)\n",
            "tensor(11.4561, grad_fn=<SumBackward0>)\n",
            "tensor(10.8885, grad_fn=<SumBackward0>)\n",
            "tensor(10.2541, grad_fn=<SumBackward0>)\n",
            "tensor(9.5630, grad_fn=<SumBackward0>)\n",
            "tensor(8.8261, grad_fn=<SumBackward0>)\n",
            "tensor(8.0551, grad_fn=<SumBackward0>)\n",
            "tensor(7.2622, grad_fn=<SumBackward0>)\n",
            "tensor(6.4599, grad_fn=<SumBackward0>)\n",
            "tensor(5.6607, grad_fn=<SumBackward0>)\n",
            "tensor(4.8773, grad_fn=<SumBackward0>)\n",
            "tensor(4.1220, grad_fn=<SumBackward0>)\n",
            "tensor(3.4066, grad_fn=<SumBackward0>)\n",
            "tensor(2.7424, grad_fn=<SumBackward0>)\n",
            "tensor(2.1396, grad_fn=<SumBackward0>)\n",
            "tensor(1.6076, grad_fn=<SumBackward0>)\n",
            "tensor(1.1548, grad_fn=<SumBackward0>)\n",
            "tensor(0.7880, grad_fn=<SumBackward0>)\n",
            "tensor(0.5129, grad_fn=<SumBackward0>)\n",
            "tensor(0.3336, grad_fn=<SumBackward0>)\n",
            "tensor(0.2527, grad_fn=<SumBackward0>)\n",
            "tensor(0.2713, grad_fn=<SumBackward0>)\n",
            "tensor(0.3888, grad_fn=<SumBackward0>)\n",
            "tensor(0.6030, grad_fn=<SumBackward0>)\n",
            "tensor(0.9104, grad_fn=<SumBackward0>)\n",
            "tensor(1.3058, grad_fn=<SumBackward0>)\n",
            "tensor(1.7827, grad_fn=<SumBackward0>)\n",
            "tensor(2.3332, grad_fn=<SumBackward0>)\n",
            "tensor(2.9485, grad_fn=<SumBackward0>)\n",
            "tensor(3.6185, grad_fn=<SumBackward0>)\n",
            "tensor(4.3325, grad_fn=<SumBackward0>)\n",
            "tensor(5.0788, grad_fn=<SumBackward0>)\n",
            "tensor(5.8456, grad_fn=<SumBackward0>)\n",
            "tensor(6.6204, grad_fn=<SumBackward0>)\n",
            "tensor(7.3908, grad_fn=<SumBackward0>)\n",
            "tensor(8.1446, grad_fn=<SumBackward0>)\n",
            "tensor(8.8697, grad_fn=<SumBackward0>)\n",
            "tensor(9.5545, grad_fn=<SumBackward0>)\n",
            "tensor(10.1882, grad_fn=<SumBackward0>)\n",
            "tensor(10.7607, grad_fn=<SumBackward0>)\n",
            "tensor(11.2630, grad_fn=<SumBackward0>)\n",
            "tensor(11.6872, grad_fn=<SumBackward0>)\n",
            "tensor(12.0265, grad_fn=<SumBackward0>)\n",
            "tensor(12.2759, grad_fn=<SumBackward0>)\n",
            "tensor(12.4314, grad_fn=<SumBackward0>)\n",
            "tensor(12.4908, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)\n",
        "print(data)\n",
        "print(loss)\n",
        "print(finalout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7PfcOMbttLY",
        "outputId": "857f95ff-7712-4493-bf00-d44f78c7aa4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0.]])\n",
            "tensor([1., 4., 3., 2., 4., 3.], requires_grad=True)\n",
            "tensor(0.0500, grad_fn=<SumBackward0>)\n",
            "tensor([1.0135, 3.8764, 2.9457, 2.0061, 3.8579, 2.8933], grad_fn=<CopySlices>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data=torch.tensor([1.,4.,3.,2.,4.,3.],requires_grad=True)\n",
        "\n",
        "node_size=5\n",
        "#generate a graph\n",
        "graph=torch.ones(node_size,node_size)\n",
        "\n",
        "#processing the graph\n",
        "post_graph=preProcessDigGraph(graph)\n",
        "\n",
        "print(post_graph)\n",
        "\n",
        "input1=torch.tensor([1.,1.,1.,1.,1.,1.],requires_grad=True)\n",
        "\n",
        "param_w=torch.rand(6,6,requires_grad=True)\n",
        "param_b=torch.rand(6,6,requires_grad=True)\n",
        "size=5\n",
        "\n",
        "epson=torch.tensor([0.0001])\n",
        "\n",
        "for j in range (2):\n",
        "  out=torch.zeros(6)\n",
        "  for i in range(6):\n",
        "     out[i]=input1[i]*param_w[1,i]+param_b[1,i]\n",
        "  #\n",
        "  out1=torch.zeros(6)\n",
        "  for i in range(6):\n",
        "    out1[i]+=param_w[3,i]*torch.relu(param_w[2,i]*out[i])+param_w[4,i]\n",
        "    \n",
        "  loss=(out1-data).pow(2).sum()\n",
        "  loss.backward()   \n",
        "  # print(param_w.grad)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    param_w-=epson*param_w.grad\n",
        "    param_b-=epson*param_b.grad\n",
        "  print(loss) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYYjsdUUitpW",
        "outputId": "5a055739-d84e-4490-ceeb-c6028954cdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor(38.4037, grad_fn=<SumBackward0>)\n",
            "tensor(38.3811, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a=torch.rand(3,4)\n",
        "c=torch.ones(3,4)\n",
        "d=3/a\n",
        "b=torch.sum(a)\n",
        "print(b)\n",
        "print(a)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0-eyJSJoG6c",
        "outputId": "a599ab63-3429-4312-e41e-f17a619b14f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.3962)\n",
            "tensor([[0.3919, 0.5140, 0.5543, 0.2181],\n",
            "        [0.5304, 0.0044, 0.6978, 0.6246],\n",
            "        [0.5244, 0.5378, 0.0690, 0.7295]])\n",
            "tensor([[  7.6557,   5.8368,   5.4118,  13.7565],\n",
            "        [  5.6558, 685.0640,   4.2991,   4.8031],\n",
            "        [  5.7209,   5.5784,  43.4747,   4.1123]])\n"
          ]
        }
      ]
    }
  ]
}